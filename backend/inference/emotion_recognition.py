<<<<<<< HEAD
import os
import numpy as np
import joblib
import librosa

from backend.features.yamnet_extract import extract_yamnet_embedding

# === è·¯å¾„ ===
MODEL_PATH = "backend/models/emotion_model.pkl"

# === åŠ è½½æ¨¡åž‹ ===
emotion_model = joblib.load(MODEL_PATH)

# === ä½ è‡ªå·±çš„æ ‡ç­¾é¡ºåº ===
emotion_labels = [
    "angry",
    "funny",
    "happy",
    "sad",
    "scary",
    "tender"
]



def predict_emotion(audio_path: str):
    """è¾“å…¥éŸ³é¢‘è·¯å¾„ï¼Œè¿”å›žæƒ…ç»ªåç§°"""

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")

    # 1. æå– YAMNet embedding
    embedding = extract_yamnet_embedding(audio_path)

    # 2. æœ‰äº› embedding æ˜¯å¤šå¸§ï¼Œå–å¹³å‡ï¼ˆè®­ç»ƒæ—¶ä¹Ÿæ˜¯è¿™ä¹ˆåšçš„ï¼‰
    if len(embedding.shape) > 1:
        embedding = embedding.mean(axis=0)

    embedding = embedding.reshape(1, -1)

    # 3. æ¨¡åž‹é¢„æµ‹
    pred_idx = emotion_model.predict(embedding)[0]
    emotion = emotion_labels[pred_idx]

    return emotion


if __name__ == "__main__":
    test_audio = "backend/test_audio.wav"

    print("ðŸ” æ­£åœ¨åˆ†æžæƒ…ç»ª...")
    emotion = predict_emotion(test_audio)
    print(f"ðŸŽµ è¯†åˆ«ç»“æžœï¼š{emotion}")
=======
import os
import numpy as np
import joblib
import librosa

from backend.features.yamnet_extract import extract_yamnet_embedding

# === è·¯å¾„ ===
MODEL_PATH = "backend/models/emotion_model.pkl"

# === åŠ è½½æ¨¡åž‹ ===
emotion_model = joblib.load(MODEL_PATH)

# === ä½ è‡ªå·±çš„æ ‡ç­¾é¡ºåº ===
emotion_labels = [
    "angry",
    "funny",
    "happy",
    "sad",
    "scary",
    "tender"
]


def predict_emotion(audio_path: str):
    """
    è¾“å…¥éŸ³é¢‘è·¯å¾„ï¼Œè¿”å›ž:
        emotion_label: str
        prob_dict: dict[label -> prob]
    """

    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"Audio file not found: {audio_path}")

    # 1. æå– YAMNet embedding
    embedding = extract_yamnet_embedding(audio_path)

    # 2. å¹³å‡å¤šå¸§ï¼ˆè®­ç»ƒä¸€è‡´ï¼‰
    if len(embedding.shape) > 1:
        embedding = embedding.mean(axis=0)

    embedding = embedding.reshape(1, -1)

    # 3. é¢„æµ‹ç±»åˆ«
    pred_idx = emotion_model.predict(embedding)[0]
    emotion = emotion_labels[pred_idx]

    # 4. é¢„æµ‹æ¦‚çŽ‡ï¼ˆXGBoost / sklearn æ¨¡åž‹æ”¯æŒ predict_probaï¼‰
    try:
        prob = emotion_model.predict_proba(embedding)[0]
        prob_dict = {emotion_labels[i]: float(prob[i]) for i in range(len(emotion_labels))}
    except Exception:
        # ä¸‡ä¸€æ¨¡åž‹æ²¡æœ‰ prob èƒ½åŠ›ï¼ˆä¸å¤ªå¯èƒ½ï¼‰
        prob_dict = {emotion_labels[i]: (1.0 if i == pred_idx else 0.0) for i in range(len(emotion_labels))}

    return emotion, prob_dict


if __name__ == "__main__":
    test_audio = "backend/test_audio.wav"

    print("ðŸ” æ­£åœ¨åˆ†æžæƒ…ç»ª...")
    emotion, prob = predict_emotion(test_audio)
    print(f"ðŸŽµ è¯†åˆ«ç»“æžœï¼š{emotion}")
    print(f"æ¦‚çŽ‡åˆ†å¸ƒï¼š{prob}")
>>>>>>> 0cf27b1 (failed_v4)
