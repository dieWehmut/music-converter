import os
import joblib
import numpy as np
from pathlib import Path
import librosa
import scipy.signal

# ‰øÆÂ§ç hann
if not hasattr(scipy.signal, "hann"):
    scipy.signal.hann = scipy.signal.windows.hann

# === ÂºïÂÖ•‰Ω†‰∏ä‰º†ÁöÑ emotion & style ‰ª£Á†Å ===
from backend.features.yamnet_extract import extract_yamnet_embedding
from .style_recognition import extract_style_features  # ‰øùËØÅ 68 Áª¥‰∏ÄËá¥


class Analyzer:
    """ÂêéÁ´ØÁªü‰∏ÄÂàÜÊûêÂô®ÔºöË¥üË¥£ Emotion + Style Êé®ÁêÜÔºåÊ®°ÂûãÂè™Âä†ËΩΩ‰∏ÄÊ¨°"""

    def __init__(self):
        ROOT = Path(__file__).resolve().parent.parent

        # ===== Emotion =====
        self.emotion_model_path = ROOT / "models" / "emotion_model.pkl"
        self.emotion_labels = [
            "angry",
            "funny",
            "happy",
            "sad",
            "scary",
            "tender"
        ]

        print("üîç Ê≠£Âú®Âä†ËΩΩ Emotion Ê®°Âûã...")
        self.emotion_model = joblib.load(self.emotion_model_path)
        print("Emotion Ê®°ÂûãÂä†ËΩΩÂÆåÊàêÔºÅ")

        # ===== Style =====
        self.style_model_path = ROOT / "models" / "style_model.pkl"
        self.style_encoder_path = ROOT / "models" / "style_label_encoder.pkl"

        print("üé∏ Ê≠£Âú®Âä†ËΩΩ Style Ê®°Âûã‰∏éÊ†áÁ≠æÁºñÁ†ÅÂô®...")
        self.style_model = joblib.load(self.style_model_path)
        self.style_encoder = joblib.load(self.style_encoder_path)
        print("Style Ê®°ÂûãÂä†ËΩΩÂÆåÊàêÔºÅ")

    # ------------------------------------------------
    # Emotion È¢ÑÊµã
    # ------------------------------------------------
    def predict_emotion(self, audio_path: str) -> str:
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Audio not found: {audio_path}")

        emb = extract_yamnet_embedding(audio_path)

        if len(emb.shape) > 1:
            emb = emb.mean(axis=0)

        emb = emb.reshape(1, -1)

        pred_idx = self.emotion_model.predict(emb)[0]
        return self.emotion_labels[pred_idx]

    # ------------------------------------------------
    # Style È¢ÑÊµã
    # ------------------------------------------------
    def predict_style(self, audio_path: str) -> str:
        feat = extract_style_features(audio_path)
        pred = self.style_model.predict(feat)[0]
        return self.style_encoder.inverse_transform([pred])[0]

    # ------------------------------------------------
    # ÊÄªÊé•Âè£Ôºö‰∏ÄÊ¨°ËøîÂõû‰∏§ËÄÖ
    # ------------------------------------------------
    def analyze(self, audio_path: str) -> dict:
        emotion = self.predict_emotion(audio_path)
        style = self.predict_style(audio_path)

        return {
            "emotion": emotion,
            "style": style
        }


# ================================================
#   Âçï‰æãÔºöÁªô FastAPI ‰ΩøÁî®
# ================================================
analyzer = Analyzer()
