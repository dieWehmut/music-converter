<<<<<<< HEAD
# backend/inference/evaluate_generated.py

from pathlib import Path
import numpy as np
from scipy.spatial.distance import jensenshannon

from backend.inference.analyze import analyzer


# =========================
# ç”¨æˆ·å¯ä¿®æ”¹
# =========================
ORIGINAL_AUDIO = r"backend/test_audio.wav"
GENERATED_AUDIO = r"backend/output/generated_final.wav"
TARGET_STYLE = "rock"
TARGET_EMOTION = "happy"
# =========================


# ---------- å·¥å…·å‡½æ•° ----------
def gain_score(gain):
    if gain >= 0.35:
        return 20
    elif gain >= 0.20:
        return 16
    elif gain >= 0.10:
        return 12
    elif gain >= 0.00:
        return 8
    else:
        return 3


def escape_score(escape):
    if escape >= 0.45:
        return 20
    elif escape >= 0.25:
        return 15
    elif escape >= 0.10:
        return 10
    elif escape >= 0:
        return 5
    else:
        return 0


def js_score(js):
    if js >= 0.40:
        return 20
    elif js >= 0.30:
        return 16
    elif js >= 0.20:
        return 12
    elif js >= 0.10:
        return 8
    else:
        return 3


def confidence_score(conf):
    if conf >= 0.75:
        return 20
    elif conf >= 0.60:
        return 15
    elif conf >= 0.45:
        return 10
    else:
        return 5


def pretty(v):
    return f"{v:+.3f}"


# =============== ä¸»ç¨‹åº ===============
def main():
    print("\n==============================")
    print("   Evaluation System v4")
    print("==============================\n")

    # ---- analyze original ----
    print("Analyzing ORIGINAL audioâ€¦\n")
    orig = analyzer.analyze(ORIGINAL_AUDIO)
    print(f"Original Style:   {orig['style']}")
    print(f"Original Emotion: {orig['emotion']}")

    # ---- analyze generated ----
    print("\nAnalyzing GENERATED audioâ€¦\n")
    if not Path(GENERATED_AUDIO).exists():
        print("âŒ File not found:", GENERATED_AUDIO)
        return

    gen = analyzer.analyze(GENERATED_AUDIO)
    print(f"Generated Style:   {gen['style']}")
    print(f"Generated Emotion: {gen['emotion']}")

    # ---- extract probabilities ----
    sp_orig = orig["style_prob"]
    sp_gen = gen["style_prob"]

    ep_orig = orig["emotion_prob"]
    ep_gen = gen["emotion_prob"]

    # ---- gains ----
    style_gain = sp_gen.get(TARGET_STYLE, 0) - sp_orig.get(TARGET_STYLE, 0)
    emo_gain = ep_gen.get(TARGET_EMOTION, 0) - ep_orig.get(TARGET_EMOTION, 0)

    # ---- escape ----
    escape = sp_orig.get(orig["style"], 0) - sp_gen.get(orig["style"], 0)

    # ---- JS divergence ----
    # Safe conversion of probability dicts to numeric vectors (handle sequence values)
    def _prob_dict_to_vector(d):
        import numpy as _np
        vec = []
        for v in (d or {}).values():
            try:
                if hasattr(v, "__iter__") and not isinstance(v, (str, bytes)):
                    vv = _np.array(v, dtype=float)
                    val = float(_np.mean(vv))
                else:
                    val = float(v)
            except Exception:
                try:
                    val = float(_np.array(v).astype(float).mean())
                except Exception:
                    val = 0.0
            vec.append(val)
        return _np.array(vec, dtype=float)

    js_style = jensenshannon(
        _prob_dict_to_vector(sp_orig),
        _prob_dict_to_vector(sp_gen)
    )

    js_emo = jensenshannon(
        _prob_dict_to_vector(ep_orig),
        _prob_dict_to_vector(ep_gen)
    )

    js_total = (js_style + js_emo) / 2

    # ---- confidence ----
    conf = (max(sp_gen.values()) + max(ep_gen.values())) / 2

    # ---- individual scores ----
    sg = gain_score(style_gain)
    eg = gain_score(emo_gain)
    esc = escape_score(escape)
    js_s = js_score(js_total)
    cf = confidence_score(conf)

    FINAL = sg + eg + esc + js_s + cf

    print("\n==============================")
    print("     SCORING RESULTS")
    print("==============================\n")

    print(f"ðŸŽ¸ Style Gain:       {pretty(style_gain)}   â†’ {sg}/20")
    print(f"ðŸŽ­ Emotion Gain:     {pretty(emo_gain)}     â†’ {eg}/20")
    print(f"â†— Escape Original:  {pretty(escape)}        â†’ {esc}/20")
    print(f"ðŸ“Š JS Divergence:    {js_total:.3f}         â†’ {js_s}/20")
    print(f"ðŸ”® Confidence:       {conf:.3f}             â†’ {cf}/20")

    print("\nâ­ Final Score:", FINAL, "/ 100")

    if FINAL >= 90:
        print("âœ¨ A+ å®Œç¾Žè½¬æ¢ï¼")
    elif FINAL >= 75:
        print("ðŸ‘ A è´¨é‡å¾ˆé«˜ï¼Œé£Žæ ¼è¿ç§»ç¨³å®š")
    elif FINAL >= 60:
        print("ðŸ™‚ B æœ‰æ˜Žæ˜¾å˜åŒ–ï¼Œä½†è¿˜å¯å†åŠ å¼º")
    elif FINAL >= 40:
        print("âš ï¸ C è½¬æ¢è¾ƒå¼±ï¼Œå¯å°è¯•é‡æ–°ç”Ÿæˆ")
    else:
        print("âŒ D å¤±è´¥ï¼Œéœ€è¦è°ƒæ•´ Prompt / Melody")

    print("\nEvaluation v4 complete.\n")


if __name__ == "__main__":
    main()
=======
# backend/inference/evaluate_generated.py

from pathlib import Path
from backend.inference.analyze import analyzer   # ä½¿ç”¨ä½ çš„ Analyzer å•ä¾‹

# ============================
# ç”¨æˆ·å¯ä¿®æ”¹è·¯å¾„
# ============================
ORIGINAL_AUDIO = r"D:\idea_python\music_project\backend\test_audio.wav"
GENERATED_AUDIO = r"D:\idea_python\music_project\backend\output\generated_style_transfer.wav"
# ============================


def compare_style_emotion(orig, gen):
    lines = []

    # Style diff
    if orig["style"] != gen["style"]:
        lines.append(f"ðŸŽ¸ Style changed: {orig['style']} â†’ {gen['style']}")
    else:
        lines.append(f"ðŸŽ¸ Style unchanged: {orig['style']}")

    # Emotion diff
    if orig["emotion"] != gen["emotion"]:
        lines.append(f"ðŸŽ­ Emotion changed: {orig['emotion']} â†’ {gen['emotion']}")
    else:
        lines.append(f"ðŸŽ­ Emotion unchanged: {orig['emotion']}")

    return "\n".join(lines)


def main():
    print("\n==============================")
    print("      Evaluate Generated Audio")
    print("==============================\n")

    # ========= åŽŸæ­Œ ==========
    print("ðŸŽ¼ Analyzing ORIGINAL audio...\n")
    orig = analyzer.analyze(ORIGINAL_AUDIO)

    print(f"Original Style:   {orig['style']}")
    print(f"Original Emotion: {orig['emotion']}")

    # ========= ç”Ÿæˆæ­Œ ==========
    print("\nðŸŽ¶ Analyzing GENERATED audio...\n")

    if not Path(GENERATED_AUDIO).exists():
        print(f"âŒ ERROR: File not found:\n{GENERATED_AUDIO}")
        return

    gen = analyzer.analyze(GENERATED_AUDIO)

    print(f"Generated Style:   {gen['style']}")
    print(f"Generated Emotion: {gen['emotion']}")

    # ========= å¯¹æ¯” ==========
    print("\n==============================")
    print("           DIFFERENCE")
    print("==============================\n")
    print(compare_style_emotion(orig, gen))

    print("\nðŸŽ¯ Evaluation complete.\n")


if __name__ == "__main__":
    main()
>>>>>>> cb02a3d (portionwise_failed_model_v3)
